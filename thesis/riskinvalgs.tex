\documentclass[11pt]{llncs}
\usepackage{preamble}

\begin{document}
  \import{thesis/}{riskinvalgsintro.tex}
  \import{thesis/definitions/}{trustreduction.tex}
  \import{thesis/definitions/}{restrictedflow.tex}

  \import{thesis/theorems/}{saturationtheorem.tex}
  \import{thesis/proofs/}{saturationproof.tex}

  \import{thesis/theorems/}{trusttransfertheorem.tex}
  \import{thesis/proofs/}{trusttransferproof.tex}

  \import{thesis/lemmas/}{flowlimitlemma.tex}
  \import{thesis/proofs/}{flowlimitproof.tex}

  \import{thesis/theorems/}{trustsavingtheorem.tex}
  \import{thesis/proofs/}{trustsavingproof.tex}

  \import{thesis/theorems/}{invtrustrednaivetheorem.tex}
  \import{thesis/proofs/}{invtrustrednaiveproof.tex}

  Until now $MaxFlow$ has been viewed purely as an algorithm. This algorithm is not guaranteed to always return the same
  flow when executed muliple times on the same graph. However, the corresponding flow value, $maxFlow$, is always the same.
  Thus $maxFlow$ can be also viewed as a function from a matrix of capacities to a non-negative real number. Under this
  perspective, we prove the following theorem. Let $\mathcal{C}$ be the family of all capacity matrices
  $C = [c_{vw}]_{V\left(\mathcal{G}\right) \times V\left(\mathcal{G}\right)}$.
  \import{thesis/theorems/}{maxflowcontinuitytheorem.tex}
  \import{thesis/proofs/}{maxflowcontinuityproof.tex}

  Here we show three naive algorithms for calculating new direct trusts so as to maintain invariable risk when paying
  a trusted party. Let $F = \sum\limits_{i=1}^{n}x_i$. To prove the correctness of the algorithms, it suffices to prove that
  \begin{equation}
  \label{naive:req1}
     \forall i \in [n], c'_i \leq x_i \mbox{ and}
  \end{equation}
  \begin{equation}
  \label{naive:req2}
     \sum\limits_{i=1}^{n}c'_i = F - V \enspace.
  \end{equation}
  \import{thesis/algorithms/}{fcfscode.tex}
  \import{thesis/proofs/}{fcfscorrectness.tex}
  \import{thesis/proofs/}{fcfscomplexity.tex}

  Note that we choose to calculate the complexity of the \texttt{length()} function as $O\left(n\right)$. Whereas this
  complexity is implementation-dependent, even with the most naive approaches it cannot be higher than $O\left(n\right)$,
  thus we use this worst-case complexity in our analysis to cover all cases. This approach will be implicitly used in all
  subsequent complexity analyses.

  \import{thesis/algorithms/}{abscode.tex}

  The function \texttt{preprocess(}$x_i$\texttt{)} returns a data structure \texttt{X} containing the set of flows
  $\left(x_i\right)$, such that the corresponding function \texttt{popMin(X)} is able to repeatedly return the index of a
  tuple consisiting of the index of the minimum element and a new data structure missing exactly the minimum element.
  Examples of such pairs of functions are:
  \begin{equation*}
  \begin{gathered}
    \begin{cases}
      \texttt{preprocess = quickSort} \\
      \texttt{popMin = (}x_1\texttt{, X}\setminus x_1\texttt{)}
    \end{cases}
    \mbox{ and} \\
    \begin{cases}
      \texttt{preprocess = FibonacciHeap} \\
      \texttt{popMin = (find-min(X),delete-min(X))}
    \end{cases} \enspace.
  \end{gathered}
  \end{equation*}
  \import{thesis/proofs/}{abscorrectness.tex}
  \import{thesis/proofs/}{abscomplexity.tex}
  \import{thesis/proofs/}{absDinfnormminproof.tex}

  \import{thesis/algorithms/}{propcode.tex}
  \import{thesis/proofs/}{propcorrectness.tex}
  \import{thesis/proofs/}{propcomplexity.tex}

  Naive algorithms result in $c'_i \leq x_i$, thus according to the Invariability Theorem (\ref{invariability}),
  $||\delta_i||_1$ is invariable for any of the possible results $C'$ of these algorithms and the resulting norm is not
  necessarily the minimum. The following algorithms concentrate on finding a configuration $C'$ that achieves $F' = F - V$
  while minimizing two $\delta_i$ norms, $||\delta_i||_\infty$ and $||\delta_i||_1$. We start with the
  $||\delta_i||_\infty$ minimizer.

  \import{thesis/algorithms/}{dinfmincode.tex}
  Since trust should be considered as a continuous unit and binary search bisects the interval containing the solution
  on each recursive call, inclusion of the $\epsilon$-parameters in \texttt{BinSearch} is necessary for the algorithm to
  complete in a finite number of steps.
  \import{thesis/algorithms/}{dinfbinsearchcode.tex}
  Let $\delta \in [0, \max\limits_{1 \leq i \leq n}{\{c_i\}}]$. Furthermore, let $C'$ such that
  $\forall i \in [n], c'_i = \max{\left(0, c_i - \delta\right)}$. We define $maxFlow\left(\delta\right) = F'$ and
  $MaxFlow\left(\delta\right) = X'$. Conventions similar to $F$, $X$ and $C$ hold for $F'$, $X'$ and $\delta$ as far as
  subscripts are concerned.
  \import{thesis/lemmas/}{maxflowmonotonicitylemma.tex}
  \import{thesis/proofs/}{maxflowmonotonicityproof.tex}
  From the previous lemma we deduce that, given a $V \in \left(0, F\right)$, if we determine a $\delta$ such that
  $maxFlow\left(\delta\right) = F - V$, this $\delta$ is unique. Let $C'$ such that
  $\forall i \in [n], c'_i = max{\left(0, c_i - \delta\right)}$. We will see that
  $\delta = \min{||\delta_i||_\infty} : F' = F - V$.
  \import{thesis/proofs/}{dinfbinsearchcorrectness.tex}
  \import{thesis/proofs/}{dinfbinsearchcomplexity.tex}
  \import{thesis/proofs/}{dinfmincorrectness.tex}
  \import{thesis/proofs/}{dinfmincomplexity.tex}

  We will now concentrate on finding a capacity configuration $C'$ such that $F' = F - V$ and that minimizes
  $\sum\limits_{i=1}^{n}\left(c_i-c'_i\right) = ||\delta_i||_1$. We treat the flow problem as a linear programming problem.
  Next we see the formulation of the problem in this form, along with a breakdown of each relevant matrix and vector.
  \import{thesis/lp/}{lpprimal.tex}
  Since we wish to optimize with regards to two objective functions, we approach the problem as follows: Initially, we ignore
  the minimization and derive the dual problem with respect to the maximisation. We then substitute the two problems'
  optimisations with an additional constraint that equates the two objective functions. Due to the Strong Duality theorem of
  linear programming, this equality can be achieved only by the common optimal solution of the two problems. We see the
  combination of constraints and variables, along with the newly introduced constraint and the previously ignored
  $||\delta_i||_1$ minimisation as a new linear problem. For every $v \in \mathcal{V}$, the solution to this problem contains
  a $c'_{Av}$. These will comprise the new configuration that player $A$ requires.

\end{document}
